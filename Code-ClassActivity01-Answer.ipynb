{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDuheyFHaVbn"
   },
   "source": [
    "## **Question 1: Discretization**\n",
    "Given the following continuous dataset of students' scores out of 100: [45, 67, 82, 90, 54, 71, 88, 62], discretize the scores into three categories: \"Low\" (0-60), \"Medium\" (61-80), and \"High\" (81-100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 955,
     "status": "ok",
     "timestamp": 1725031159157,
     "user": {
      "displayName": "parisa hajibabaee",
      "userId": "05645070794075408908"
     },
     "user_tz": 240
    },
    "id": "Zo_Q-e2NaONS",
    "outputId": "cbb160db-00cc-4384-a7d7-838e1f32f739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low', 'Medium', 'High', 'High', 'Low', 'Medium', 'High', 'Medium']\n",
      "Categories (3, object): ['Low' < 'Medium' < 'High']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Given continuous dataset of scores\n",
    "scores = [45, 67, 82, 90, 54, 71, 88, 62]\n",
    "\n",
    "# Define the bins and labels\n",
    "bins = [0, 60, 80, 100] #(these define the ranges: 0-60, 61-80, 81-100)\n",
    "labels = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "# Discretize the scores\n",
    "# Hint: pd.cut(): This function is used to segment and sort data values into discrete bins or intervals.\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.cut.html\n",
    "\n",
    "discretized_scores = pd.cut(scores,bins= bins, labels=labels) #use pd.cut()\n",
    "\n",
    "print(discretized_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kj617UCar0b"
   },
   "source": [
    "## **Question 2: Numeric Coding of Nominal Attributes**\n",
    "Convert the following list of car brands into numeric codes: [\"Toyota\", \"Ford\", \"Honda\", \"Toyota\", \"BMW\", \"Ford\", \"Honda\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3139,
     "status": "ok",
     "timestamp": 1725029208090,
     "user": {
      "displayName": "parisa hajibabaee",
      "userId": "05645070794075408908"
     },
     "user_tz": 240
    },
    "id": "j2bJkbjja7JM",
    "outputId": "2470723e-2d90-4ae8-971c-bef8de69190e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 2 3 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Import the LabelEncoder class from the sklearn.preprocessing module in the scikit-learn library.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "# Encoding Categorical Data: LabelEncoder is used to convert categorical (nominal) data into numeric labels.\n",
    "# It assigns a unique integer to each category, transforming strings or other types of categories into numerical values.\n",
    "\n",
    "# Given list of car brands\n",
    "car_brands = [\"Toyota\", \"Ford\", \"Honda\", \"Toyota\", \"BMW\", \"Ford\", \"Honda\"]\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder() #This line initializes an instance of the LabelEncoder class.\n",
    "# Purpose: The LabelEncoder is ready to be used for converting categorical data into numeric labels.\n",
    "# It prepares the encoder but doesnâ€™t yet process any data.\n",
    "\n",
    "\n",
    "# Convert car brands to numeric codes\n",
    "numeric_codes = label_encoder.fit_transform(car_brands) #use .fit_transform()\n",
    "# fit_transform() is a combined method that both \"fits\" the encoder to the data and \"transforms\" the data in one step.\n",
    "# Fitting: The fit part of fit_transform scans through the data (car_brands) and identifies all unique categories (e.g., \"Toyota\", \"Ford\", \"Honda\", \"BMW\").\n",
    "# Transforming: The transform part assigns a unique integer label to each category:\n",
    "# For example, it might encode \"Toyota\" as 3, \"Ford\" as 1, \"Honda\" as 2, and \"BMW\" as 0.\n",
    "\n",
    "print(numeric_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE2YjwSRjnT4"
   },
   "source": [
    "Here are some functions and methods similar to LabelEncoder that can be used for numeric coding of categorical data:\n",
    "\n",
    "**1. OneHotEncoder (from sklearn.preprocessing)**\n",
    "\n",
    "**Purpose:** Converts categorical data into a one-hot numeric array, where each category is represented by a binary vector. Each column represents a category with 1 indicating presence and 0 absence.\n",
    "\n",
    "**2. OrdinalEncoder (from sklearn.preprocessing)**\n",
    "\n",
    "**Purpose:** Similar to LabelEncoder, but works on multiple columns and encodes each category as an ordinal number based on the order provided or encountered.\n",
    "\n",
    "\n",
    "**3. pd.factorize (from pandas)**\n",
    "\n",
    "**Purpose:** Encodes categorical data into numeric codes, similar to LabelEncoder, but is available directly in pandas and handles missing values by assigning a unique code for NaNs.\n",
    "\n",
    "**4. get_dummies (from pandas)**\n",
    "\n",
    "**Purpose:** Similar to OneHotEncoder, get_dummies creates one-hot encoded columns from categorical data, making it easy to incorporate categorical data into models.\n",
    "\n",
    "**5. ColumnTransformer (from sklearn.compose)**\n",
    "\n",
    "**Purpose:** Allows for more complex preprocessing pipelines where different encoders can be applied to different columns within the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0CM18CCbQfJ"
   },
   "source": [
    "##**Question 3: Data Preprocessing and Cleansing**\n",
    "You have a dataset with missing values in the \"Age\" column. The values are [25, 30, NaN, 22, 28, NaN, 35]. Describe how you would handle these missing values and justify your approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1725029234524,
     "user": {
      "displayName": "parisa hajibabaee",
      "userId": "05645070794075408908"
     },
     "user_tz": 240
    },
    "id": "5FosWNLBbWLO",
    "outputId": "60715832-d21a-4121-fda4-d974bf86f173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-filled: [25.0, 30.0, 28.0, 22.0, 28.0, 28.0, 35.0]\n",
      "Median-filled: [25.0, 30.0, 28.0, 22.0, 28.0, 28.0, 35.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Given dataset with missing values\n",
    "# pd.Series(): This function from the pandas library creates a one-dimensional array-like object called a Series, which can hold data of any type (integers, floats, strings, etc.).\n",
    "ages = pd.Series([25, 30, np.nan, 22, 28, np.nan, 35]) #np.nan (which stands for \"Not a Number\" and represents missing values in the dataset\n",
    "\n",
    "# Option 1: Fill missing values with the mean\n",
    "ages_mean_filled = ages.fillna(ages.mean())\n",
    "\n",
    "# Option 2: Fill missing values with the median\n",
    "ages_median_filled = ages.fillna(ages.median())\n",
    "\n",
    "\n",
    "\n",
    "# .tolist(): This method converts the pandas Series into a Python list.\n",
    "print(\"Mean-filled:\", ages_mean_filled.tolist())\n",
    "print(\"Median-filled:\", ages_median_filled.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWIIl8YnbZrL"
   },
   "source": [
    "## **Question 4: Feature Selection**\n",
    "Using the California housing dataset, you want to identify the top 3 most relevant features for predicting the median house value. You decide to use the SelectKBest feature selection method with the f_regression scoring function. Write the code to perform this feature selection and identify the selected feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2025,
     "status": "ok",
     "timestamp": 1725029277081,
     "user": {
      "displayName": "parisa hajibabaee",
      "userId": "05645070794075408908"
     },
     "user_tz": 240
    },
    "id": "v45xF5lSbW9Q",
    "outputId": "85e65e6f-576e-4a7b-9291-aa514446cfc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['MedInc', 'AveRooms', 'Latitude']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html\n",
    "\n",
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data  # Features (input data)\n",
    "y = housing.target  # Target variable (what we want to predict)\n",
    "\n",
    "# Apply feature selection using SelectKBest\n",
    "selector = SelectKBest(score_func=f_regression, k=3)\n",
    "# Initializes the SelectKBest feature selector:\n",
    "# - `score_func=f_regression`: Uses the F-test (ANOVA) regression score function to evaluate the importance of each feature.\n",
    "# - `k=3`: Specifies that we want to select the top 3 features based on the scoring function.\n",
    "\n",
    "X_selected = selector.fit_transform(X, y) #use .fit_transform()\n",
    "# Fits the selector to the data (X, y) and transforms X to contain only the selected features.\n",
    "# - The fit process evaluates each feature using the score function.\n",
    "# - The transform process reduces X to the k best features based on the scores.\n",
    "\n",
    "# Get selected feature indices\n",
    "selected_features = selector.get_support(indices=True) #use .get_support(indices=True)\n",
    "# `get_support(indices=True)` retrieves the indices of the selected features.\n",
    "# - It returns an array of indices corresponding to the top k features.\n",
    "\n",
    "# Map indices to feature names\n",
    "selected_feature_names = [housing.feature_names[i] for i in selected_features]\n",
    "# Uses the indices of selected features to get their names from `housing.feature_names`.\n",
    "# - `housing.feature_names` contains the names of all features in the dataset.\n",
    "# - This list comprehension builds a list of names for the selected features.\n",
    "\n",
    "# Print the names of the selected features\n",
    "print(\"Selected features:\", selected_feature_names)\n",
    "# Outputs the names of the top 3 features identified as most relevant for predicting the target variable.\n",
    "# (Note: The actual selected features may vary depending on the scoring function results.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6CzhDRvi5db"
   },
   "source": [
    "There are several other methods similar to SelectKBest for feature selection in machine learning. Here are some common alternatives:\n",
    "\n",
    "**1. Recursive Feature Elimination (RFE):**\n",
    "\n",
    "**Description:** RFE works by recursively removing the least important features and building the model repeatedly until the specified number of features is reached.\n",
    "\n",
    "**Use Case:** Itâ€™s useful when you want a model-based approach that considers feature interactions.\n",
    "\n",
    "\n",
    "**2. Feature Importance from Tree-Based Models:**\n",
    "**Description:** Tree-based models like Random Forests and Gradient Boosting provide feature importance scores that can be used to select the most important features.\n",
    "**Use Case:** Suitable when using tree-based models for prediction, as they naturally rank feature importance.\n",
    "\n",
    "**3. L1-Based Feature Selection (Lasso Regularization):**\n",
    "**Description:** Uses L1 regularization to shrink some coefficients to zero, effectively selecting features that contribute most to the model.\n",
    "**Use Case:** Good for high-dimensional datasets where many features are irrelevant.\n",
    "\n",
    "\n",
    "**4. Mutual Information Feature Selection:**\n",
    "**Description:** Selects features based on their mutual information score with the target variable, which measures the dependency between variables.\n",
    "**Use Case:** Useful when you want to capture non-linear relationships between features and the target.\n",
    "\n",
    "**5. Sequential Feature Selection:**\n",
    "\n",
    "**Description:** Adds (forward selection) or removes (backward selection) features sequentially based on model performance.\n",
    "\n",
    "**Use Case:** Useful when model performance is the key criterion for feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCrXOxAFbq4e"
   },
   "source": [
    "## **Question 5: Data Transformation**\n",
    "Consider a dataset where the \"Income\" attribute is heavily skewed. What transformation technique would you apply to normalize this data, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1725029291871,
     "user": {
      "displayName": "parisa hajibabaee",
      "userId": "05645070794075408908"
     },
     "user_tz": 240
    },
    "id": "tRAGlASmbif3",
    "outputId": "f8ca2081-5de2-4d6c-e4dc-c17e8ddb2f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10.308953\n",
      "1    10.714418\n",
      "2    13.122363\n",
      "3    11.156251\n",
      "4    11.695247\n",
      "5    10.126631\n",
      "6    12.611538\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Given dataset with skewed income attribute\n",
    "income = pd.Series([30000, 45000, 500000, 70000, 120000, 25000, 300000])\n",
    "\n",
    "# Apply logarithmic transformation\n",
    "log_income = np.log(income) #use np.log()\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.log.html\n",
    "\n",
    "print(log_income)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3xT_XJpgJRm"
   },
   "source": [
    "Besides the logarithmic transformation, there are several other transformations you can apply to skewed data to make it more normally distributed or manageable for analysis. Here are some common transformations:\n",
    "\n",
    "\n",
    "**1. Square Root Transformation:**\n",
    "\n",
    "\n",
    "This transformation can help reduce the skewness of moderately skewed data.\n",
    "\n",
    "\n",
    "It is less aggressive than a log transformation and works well with positive values.\n",
    "\n",
    "\n",
    "**2. Cube Root Transformation:**\n",
    "\n",
    "\n",
    "The cube root transformation is another option for reducing skewness.\n",
    "\n",
    "\n",
    "It can handle both positive and negative values, unlike the logarithmic transformation.\n",
    "\n",
    "\n",
    "**3. Box-Cox Transformation:**\n",
    "\n",
    "\n",
    "The Box-Cox transformation is a more flexible transformation that can be tuned by a parameter (lambda) to reduce skewness.\n",
    "\n",
    "\n",
    "It requires all values to be positive and is often used to transform data closer to normality.\n",
    "\n",
    "\n",
    "**4. Reciprocal Transformation:**\n",
    "\n",
    "\n",
    "The reciprocal (or inverse) transformation is used when data is very positively skewed.\n",
    "\n",
    "\n",
    "This transformation should be used carefully as it can overly compress larger values.\n",
    "\n",
    "\n",
    "**5. Exponential Transformation:**\n",
    "\n",
    "\n",
    "An exponential transformation, like raising the values to a power less than one (e.g., raising to 0.5 or 0.3), can also be used to transform data.\n",
    "\n",
    "\n",
    "For heavily skewed data, this approach can moderate large values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fri4g1RYhaGh"
   },
   "source": [
    "**Differences Between Transformation Methods and Choosing the Best One**\n",
    "\n",
    "\n",
    "Data transformations adjust the distribution of skewed data. Hereâ€™s an overview of common transformations and guidance on selecting the best one for your data:\n",
    "\n",
    "**1. Logarithmic Transformation**\n",
    "\n",
    "**Effect:** Reduces right skewness, compressing large values more.\n",
    "\n",
    "**Use When:** Data is positively skewed with all positive values.\n",
    "\n",
    "**Best For:** Data with a wide range of values, clustered at the lower end.\n",
    "\n",
    "\n",
    "**2. Square Root Transformation**\n",
    "\n",
    "\n",
    "**Effect:** Moderately reduces skewness by compressing larger values.\n",
    "\n",
    "**Use When:** Data has moderate positive skewness.\n",
    "\n",
    "**Best For:** Non-negative data needing a less aggressive transformation.\n",
    "\n",
    "\n",
    "**3. Cube Root Transformation**\n",
    "\n",
    "\n",
    "**Effect:** Handles both positive and negative values; gentler adjustment.\n",
    "\n",
    "**Use When:** Data includes negatives or requires mild transformation.\n",
    "\n",
    "**Best For:** Data with both positive and negative values or needing a softer adjustment.\n",
    "\n",
    "\n",
    "**4. Box-Cox Transformation**\n",
    "\n",
    "**Effect:** Adjusts data toward normality with a tunable parameter (lambda).\n",
    "\n",
    "**Use When:** Data is strictly positive, aiming for normal distribution.\n",
    "\n",
    "**Best For:** Cases requiring normality for parametric tests.\n",
    "\n",
    "**5. Reciprocal Transformation**\n",
    "\n",
    "**Effect:** Strongly compresses large values; can overly shrink data.\n",
    "\n",
    "\n",
    "**Use When:** Data is highly skewed and all positive.\n",
    "\n",
    "\n",
    "**Best For:** Extreme skewness requiring strong transformation.\n",
    "\n",
    "\n",
    "**6. Exponential Transformation (Power Transformation)**\n",
    "\n",
    "\n",
    "**Effect:** Uses fractional powers for milder adjustments than logs.\n",
    "\n",
    "\n",
    "**Use When:** Data has moderate skewness and is non-negative.\n",
    "\n",
    "\n",
    "**Best For:** Flexible, mild transformations without drastic changes.\n",
    "\n",
    "\n",
    "**How to Choose the Best Transformation:**\n",
    "\n",
    "\n",
    "**Visual Inspection:**\n",
    "\n",
    "Use histograms, boxplots, or QQ plots to assess skewness.\n",
    "\n",
    "\n",
    "**Statistical Tests:**\n",
    "\n",
    "Use tests like Shapiro-Wilk or Anderson-Darling for normality.\n",
    "\n",
    "\n",
    "**Try Multiple Transformations:**\n",
    "\n",
    "Apply and visually inspect multiple transformations; use histograms or QQ plots to compare.\n",
    "\n",
    "**Evaluate with Your Model:**\n",
    "\n",
    "Test transformed data in your model and compare metrics like R-squared, MSE, or cross-validation scores.\n",
    "\n",
    "**Check Distribution Characteristics:**\n",
    "\n",
    "Evaluate mean, variance, skewness, and kurtosis of transformed data.\n",
    "Context and Practicality:\n",
    "\n",
    "Consider how interpretable and practical the transformed data is for your specific needs.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMlguaKNrlkSN1vJJDXJx6l",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
